# üöÄ Gu√≠a Post-Deployment - Configuraci√≥n Inicial

Esta gu√≠a es para **DevOps** despu√©s de levantar exitosamente los contenedores en producci√≥n.

**IMPORTANTE:** La aplicaci√≥n NO ser√° funcional hasta completar estos pasos. Los contenedores estar√°n corriendo, pero necesitas configurar servicios externos y crear el primer datasource.

---

## ‚úÖ Pre-requisitos

Antes de comenzar, aseg√∫rate de que:

- [ ] Todos los contenedores est√°n corriendo (`docker compose -f docker-compose.prod.yml ps`)
- [ ] El backend responde en `https://api.TU_DOMINIO/api/health`
- [ ] El frontend carga en `https://TU_DOMINIO`
- [ ] Los certificados SSL est√°n activos (Traefik + Let's Encrypt)

---

## üìã Paso 1: Obtener API Key de Google Gemini

La aplicaci√≥n **requiere** una API Key de Google Gemini para:
- Generar embeddings de texto (b√∫squeda sem√°ntica)
- An√°lisis de im√°genes
- Detecci√≥n de duplicados

### C√≥mo Obtener la API Key:

1. **Ir a Google AI Studio:**
   ```
   https://aistudio.google.com/app/apikey
   ```

2. **Crear un nuevo proyecto** (si no tienes uno)

3. **Generar API Key:**
   - Click en "Create API Key"
   - Selecciona tu proyecto
   - Copia la API key generada

4. **Actualizar .env.production:**
   ```bash
   # En el servidor
   cd ~/proyectos/bip2
   nano .env.production

   # Actualizar esta l√≠nea:
   GEMINI_API_KEY=TU_API_KEY_AQUI
   ```

5. **Reiniciar el backend:**
   ```bash
   docker compose -f docker-compose.prod.yml restart backend
   ```

6. **Verificar:**
   ```bash
   # Debe aparecer "Gemini AI initialized" en los logs
   docker logs bip-backend | grep Gemini
   ```

### L√≠mites de la API:

- **Free tier:** 15 requests/minuto, 1,500 requests/d√≠a
- **Paid tier:** Consultar https://ai.google.dev/pricing

Para producci√≥n se recomienda:
- Configurar billing en Google Cloud
- Aumentar cuotas si es necesario
- Monitorear uso

---

## üìã Paso 2: Verificar Conectividad de Servicios

### 2.1 Health Check Completo

```bash
curl https://api.TU_DOMINIO/api/health
```

**Respuesta esperada:**
```json
{
  "status": "healthy",
  "timestamp": "2025-10-31T...",
  "services": {
    "database": {
      "healthy": true,
      "message": "Database is healthy"
    },
    "qdrant": {
      "healthy": true,
      "message": "Qdrant is healthy"
    },
    "redis": {
      "healthy": true,
      "message": "Redis is healthy"
    }
  }
}
```

### 2.2 Si Qdrant aparece "unhealthy":

```bash
# Verificar que Qdrant est√© corriendo
docker logs bip-qdrant

# Verificar conectividad desde el backend
docker exec bip-backend wget -qO- http://qdrant:6333/health
```

---

## üìã Paso 3: Configurar el Primer Datasource

La aplicaci√≥n necesita al menos **un datasource** configurado para ser funcional.

### 3.1 Requisitos del Datasource

Necesitas acceso a una base de datos con datos de productos. Soportados:
- **MS SQL Server** (recomendado para EFC)
- **MySQL**
- **PostgreSQL**

### 3.2 Informaci√≥n Necesaria

Antes de crear el datasource, ten a mano:

- **Host:** Direcci√≥n IP o hostname del servidor de base de datos
- **Puerto:** Ej: 1433 (SQL Server), 3306 (MySQL), 5432 (PostgreSQL)
- **Usuario:** Usuario con permisos de lectura
- **Contrase√±a:** Contrase√±a del usuario
- **Nombre de BD:** Nombre de la base de datos
- **Query SQL:** Query que devuelve los productos (ver ejemplos abajo)

### 3.3 Acceder a Swagger UI

```
https://api.TU_DOMINIO/api/docs
```

### 3.4 Crear Datasource v√≠a API

**Opci√≥n A: Usar Swagger UI (Recomendado)**

1. Ir a `https://api.TU_DOMINIO/api/docs`
2. Expandir `POST /api/datasources`
3. Click en "Try it out"
4. Pegar el JSON de ejemplo (ver abajo)
5. Click en "Execute"

**Opci√≥n B: Usar cURL**

```bash
curl -X POST https://api.TU_DOMINIO/api/datasources \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Cat√°logo EFC - Productos Industriales",
    "type": "mssql",
    "connectionConfig": {
      "host": "TU_SQL_SERVER_IP",
      "port": 1433,
      "user": "TU_USUARIO",
      "password": "TU_PASSWORD",
      "database": "NOMBRE_BD",
      "options": {
        "encrypt": true,
        "trustServerCertificate": true,
        "connectionTimeout": 30000,
        "requestTimeout": 30000
      }
    },
    "queryTemplate": "SELECT codigo_producto AS id, descripcion, marca, categoria, precio, stock FROM productos WHERE estado = '\''A'\'' ORDER BY codigo_producto OFFSET {{offset}} ROWS FETCH NEXT {{limit}} ROWS ONLY",
    "fieldMapping": {
      "id": "codigo",
      "descripcion": "descripcion",
      "marca": "marca",
      "categoria": "categoria",
      "precio": "precio",
      "stock": "stock"
    },
    "idField": "id",
    "embeddingFields": ["descripcion", "marca", "categoria"],
    "qdrantCollection": "catalogo_productos",
    "batchSize": 100,
    "batchDelay": 1000,
    "syncSchedule": "0 2 * * *",
    "description": "Cat√°logo principal de productos industriales"
  }'
```

### 3.5 Notas Importantes sobre el Query

**El query debe incluir:**
- `{{offset}}` y `{{limit}}` para paginaci√≥n
- Un campo √∫nico como ID (ej: c√≥digo de producto)
- Campos de texto para generar embeddings (descripci√≥n, marca, etc.)

**Ejemplo para SQL Server:**
```sql
SELECT
  codigo AS id,
  descripcion,
  marca,
  categoria
FROM productos
WHERE estado = 'A'
ORDER BY codigo
OFFSET {{offset}} ROWS
FETCH NEXT {{limit}} ROWS ONLY
```

**Ejemplo para MySQL:**
```sql
SELECT
  codigo AS id,
  descripcion,
  marca,
  categoria
FROM productos
WHERE estado = 'A'
ORDER BY codigo
LIMIT {{limit}} OFFSET {{offset}}
```

---

## üìã Paso 4: Probar la Conexi√≥n del Datasource

```bash
# Obtener el ID del datasource creado
curl https://api.TU_DOMINIO/api/datasources

# Probar la conexi√≥n (reemplazar DATASOURCE_ID)
curl -X POST https://api.TU_DOMINIO/api/datasources/DATASOURCE_ID/test
```

**Respuesta esperada:**
```json
{
  "success": true,
  "message": "Connection successful",
  "rowCount": 1234,
  "sampleData": [...]
}
```

---

## üìã Paso 5: Sincronizar Datos (Primera Sincronizaci√≥n)

Una vez que el datasource est√° configurado y probado:

```bash
# Iniciar sincronizaci√≥n completa
curl -X POST https://api.TU_DOMINIO/api/sync/full/DATASOURCE_ID
```

**Respuesta:**
```json
{
  "jobId": "uuid-del-job",
  "status": "queued",
  "message": "Full sync job created"
}
```

### Monitorear el Progreso:

```bash
# Ver estado del job
curl https://api.TU_DOMINIO/api/sync/jobs/JOB_ID

# Ver logs en tiempo real
docker logs -f bip-backend | grep "Sync"
```

**Tiempo estimado:**
- 10,000 productos: ~5-10 minutos
- 100,000 productos: ~30-60 minutos
- 200,000 productos: ~1-2 horas

---

## üìã Paso 6: Verificar que la B√∫squeda Funcione

### 6.1 Probar B√∫squeda de Texto

```bash
curl -X POST https://api.TU_DOMINIO/api/search/text \
  -H "Content-Type: application/json" \
  -d '{
    "query": "motor el√©ctrico",
    "collections": ["catalogo_productos"],
    "limit": 5
  }'
```

**Respuesta esperada:**
```json
{
  "results": [
    {
      "id": "PROD001",
      "descripcion": "Motor el√©ctrico trif√°sico 5HP",
      "marca": "WEG",
      "score": 0.95,
      ...
    }
  ],
  "total": 156,
  "query": "motor el√©ctrico"
}
```

### 6.2 Probar desde el Frontend

1. Ir a `https://TU_DOMINIO`
2. Usar la barra de b√∫squeda
3. Ingresar: "motor el√©ctrico" o cualquier producto
4. Verificar que aparezcan resultados

---

## üìã Paso 7: Configurar Sincronizaci√≥n Autom√°tica (Opcional)

El datasource ya tiene configurado `syncSchedule: "0 2 * * *"` (todos los d√≠as a las 2 AM).

Para verificar que el cron est√° activo:

```bash
# Ver logs del scheduler
docker logs bip-backend | grep "Scheduled sync"
```

---

## ‚úÖ Checklist Final de Verificaci√≥n

- [ ] API Key de Gemini configurada y funcionando
- [ ] Health check muestra todos los servicios "healthy"
- [ ] Al menos un datasource creado y probado
- [ ] Primera sincronizaci√≥n completada exitosamente
- [ ] B√∫squeda de texto devuelve resultados
- [ ] Frontend carga y muestra resultados de b√∫squeda
- [ ] Certificados SSL activos (candado verde en el navegador)
- [ ] Logs no muestran errores cr√≠ticos

```bash
# Verificaci√≥n r√°pida
curl https://api.TU_DOMINIO/api/health
curl https://api.TU_DOMINIO/api/datasources
curl https://api.TU_DOMINIO/api/collections
```

---

## üîß Troubleshooting

### Problema: "Gemini API failed"

```bash
# Verificar que la API key est√° configurada
docker exec bip-backend printenv | grep GEMINI_API_KEY

# Verificar logs
docker logs bip-backend | grep -i gemini
```

**Soluci√≥n:**
- Verificar que la API key es v√°lida
- Verificar que no has excedido los l√≠mites de cuota
- Reiniciar el backend: `docker compose -f docker-compose.prod.yml restart backend`

### Problema: "Database connection failed"

```bash
# Verificar conectividad
docker exec bip-backend ping -c 3 TU_DB_HOST

# Verificar credenciales
# Aseg√∫rate de que el servidor SQL permite conexiones desde la IP del servidor
```

### Problema: "Sync job failed"

```bash
# Ver errores del job
curl https://api.TU_DOMINIO/api/sync/errors/JOB_ID

# Ver logs detallados
docker logs bip-backend | grep -A 20 "Sync error"
```

---

## üìû Soporte

Si encuentras problemas:

1. **Revisar logs:**
   ```bash
   docker compose -f docker-compose.prod.yml logs -f
   ```

2. **Verificar documentaci√≥n:**
   - `DEPLOYMENT.md` - Gu√≠a completa de deployment
   - `QUICK_START.md` - Gu√≠a r√°pida
   - Swagger UI - Documentaci√≥n de API

3. **Contacto:**
   - Email: alannreyesj@gmail.com
   - GitHub Issues: https://github.com/alannreyes/bip2/issues

---

## üéâ ¬°Sistema Funcional!

Una vez completados todos los pasos, tendr√°s:

- ‚úÖ Sistema de b√∫squeda sem√°ntica funcionando
- ‚úÖ Cat√°logo sincronizado y actualizado
- ‚úÖ B√∫squeda por texto operativa
- ‚úÖ Sincronizaciones autom√°ticas configuradas
- ‚úÖ Monitoreo de salud disponible
- ‚úÖ Interfaz web accesible

**La aplicaci√≥n est√° ahora completamente funcional y lista para usar.**
